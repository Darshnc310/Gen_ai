{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c729322b-6058-4cf6-b902-cbaa50ee2885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Zero-Shot Example ===\n",
      "--- Sending Prompt to LLM ---\n",
      "Translate the following text to French: 'Hello, how are you?'\n",
      "-------------------------------\n",
      "LLM Response: Bonjour. Comment ça va?\n",
      "\n",
      "=== Running Few-Shot Example ===\n",
      "--- Sending Prompt to LLM ---\n",
      "\n",
      "Classify the sentiment of the text as 'Positive', 'Negative', or 'Neutral'.\n",
      "\n",
      "Text: \"The food was cold and the service was slow.\"\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: \"I'm not sure how I feel about the new update.\"\n",
      "Sentiment: Neutral\n",
      "\n",
      "Text: \"This is the best movie I have seen all year!\"\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: \"I really enjoyed the first half of the book.\"\n",
      "Sentiment:\n",
      "\n",
      "-------------------------------\n",
      "LLM Response: Positive\n",
      "\n",
      "=== Running Chain-of-Thought Example ===\n",
      "--- Sending Prompt to LLM ---\n",
      "\n",
      "Q: The cafeteria had 23 apples. If they used 20 to make lunch\n",
      "and bought 6 more, how many apples do they have?\n",
      "\n",
      "A: Let's think step by step.\n",
      "\n",
      "-------------------------------\n",
      "LLM Response:\n",
      "Step 1: The cafeteria starts with 23 apples.\n",
      "Step 2: They use 20, so 23 - 20 = 3 apples.\n",
      "Step 3: They buy 6 more, so 3 + 6 = 9 apples.\n",
      "The final answer is 9.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This example uses a conceptual function `call_llm_api`.\n",
    "# In the real world, this would be `openai.ChatCompletion.create()`\n",
    "# or a call to Google's Gemini API, etc.\n",
    "\n",
    "def call_llm_api(prompt_text):\n",
    "    \"\"\"\n",
    "    A placeholder function to simulate calling an LLM API.\n",
    "    In a real application, this would contain your API key,\n",
    "    model name ('gpt-4', 'gemini-1.5-pro'), and network request code.\n",
    "    \"\"\"\n",
    "    print(\"--- Sending Prompt to LLM ---\")\n",
    "    print(prompt_text)\n",
    "    print(\"-------------------------------\")\n",
    "    # Simulate a response based on the prompt type\n",
    "    if \"Let's think step by step\" in prompt_text:\n",
    "        return (\"Step 1: The cafeteria starts with 23 apples.\\n\"\n",
    "                \"Step 2: They use 20, so 23 - 20 = 3 apples.\\n\"\n",
    "                \"Step 3: They buy 6 more, so 3 + 6 = 9 apples.\\n\"\n",
    "                \"The final answer is 9.\")\n",
    "    elif \"Sentiment:\" in prompt_text:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Bonjour. Comment ça va?\"\n",
    "\n",
    "# --- Technique 1: Zero-Shot Prompting ---\n",
    "# Simple, direct instruction. No examples.\n",
    "zero_shot_prompt = \"Translate the following text to French: 'Hello, how are you?'\"\n",
    "\n",
    "print(\"\\n=== Running Zero-Shot Example ===\")\n",
    "response_zero_shot = call_llm_api(zero_shot_prompt)\n",
    "print(f\"LLM Response: {response_zero_shot}\\n\")\n",
    "\n",
    "\n",
    "# --- Technique 2: Few-Shot Prompting ---\n",
    "# Provide examples (the \"shots\") to guide the model on format.\n",
    "few_shot_prompt = \"\"\"\n",
    "Classify the sentiment of the text as 'Positive', 'Negative', or 'Neutral'.\n",
    "\n",
    "Text: \"The food was cold and the service was slow.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Text: \"I'm not sure how I feel about the new update.\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Text: \"This is the best movie I have seen all year!\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Text: \"I really enjoyed the first half of the book.\"\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Running Few-Shot Example ===\")\n",
    "response_few_shot = call_llm_api(few_shot_prompt)\n",
    "print(f\"LLM Response: {response_few_shot}\\n\")\n",
    "\n",
    "\n",
    "# --- Technique 3: Chain-of-Thought (CoT) Prompting ---\n",
    "# Ask the model to reason step-by-step to solve a logic problem.\n",
    "cot_prompt = \"\"\"\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch\n",
    "and bought 6 more, how many apples do they have?\n",
    "\n",
    "A: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Running Chain-of-Thought Example ===\")\n",
    "response_cot = call_llm_api(cot_prompt)\n",
    "print(f\"LLM Response:\\n{response_cot}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715d1e2-13ef-444f-9604-21c2c3eb3a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tallyai",
   "language": "python",
   "name": "tallyai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
